---------------------------------------------------------------------------- Advanced: Helm -----------------------------------------------------------

*) Helm: 
        - Pks kukbernetes (obj manifests and configs) in -> Helm's Chart 
        - maintains the lifecycle of deployment in K8s (named release)
        - 2 components: helm (CLI) & Tiller (server side) 
        - public repos for helm charts
    Usage: 
       - install helm -> initialize helm for cluster -> install helm chart (like: helm install stable/wordpress) -> helm applies manifests (in template) and specific config values
        (values.yaml file) or default ones using also metadata (in chart.yaml and requirements.yaml)
Exo: 
       - $kubectl apply -f tiller-serviceaccount.yaml (in my local directorie: exists) => to Set-UP Tiller in the new cluster;  
       - $helm init --service-account AcctName => install helm to the Kubernetes cluster; 
       - $kubectl get deploy,svc tiller-deploy -n kube-system : chek tiller is up and running on cluster (== kubectl get deployment tiller-deploy -n xxxx)
       - $helm install stable/bookstack (install the charts bookstack)
       - $helm status name_release (check status w fill infos)
       - $kubectl get pv (persistent volumes)
   To change a value in release, we should upgrade it, exemple: 
       - $helm upgrade --set service.type='LoadBalancer' dozing-robin stable/bookstack /to expose laodbalancer to web service;
       - $helm list (list our releases on the cluster ) 
       - $helm delete release-name; delete all pods/deployments/services/statefulsets/ relative to the release
   Install a Chart with a Local values.yaml file: 
       - $helm install -f values.yaml stable/bookstack --name taikbook
--------------------------------------------------------------------------- Ingress Control ---------------------------------------------------------------
*) Ingress: 
      - Expose traffic in Customized way than the LoadBalancer; 
      - for each service -> we configure an Ingress Object (defines How to route traffic): access the service from Outside Cluster 
      - Designed for HTTP/s; securing w/ SSL, Routing to different Backend Systems based on: host names or URL paths (name/path -based routing)
      - Define Ingress Resource ==> Ingress Controller: routes Traffic based on resources; 
      - NGINX Ingress controller deployment is popular choice; 
      - public ----> LoadBalancer(GC) -----> Ingress Controller ---> [ Service1,2,...,n  --------> Pods1,2,...,n ]_GKCluster 
      - Ingress Controller checks Ingress resources to route traffic to services 
      - resolve with curl: 
        $curl --resolve myapp.example.com:80:35.238.32.151 http://myapp.example.com : qd on cherhe la page, elle a ete mappe avec le publicIP de l Ingress ctrler
         qui va router le traffic au bon service;
-------------------------------------------------------------------------------------------------Cluster high Availability ---------------------------------------------------------
*) workloads highly available: Create Regional GKE Clusters: 
*) Storage highly available: Regional Persistent Storage; use nodeAffinity and nodeSelectorTerms
*) maximum availability: run application accross  Multi-cluster Ingress (laodbalancer) across multiple GKE clusters
   - use of kubemci;
   exo:
    - $KUBECONFIG=clusters.yaml gcloud container clusters create --zone=us-east4-a cluster-1 (create 1st cluster)
    - $KUBECONFIG=clusters.yaml gcloud container clusters create --zone=europe-west1-c cluster-2 (create 2nd one)
    Ceci cree un fichier clusters.yaml avec  ts les details des clusters avec leurs contextes
    - $ kubectl --kubeconfig=clusters.yaml --context=project-xxxx_us-east4-a_cluster-1 apply -f manifests/
             - chercher le context ds clusters.yaml et appliquer tous les manifests (directory btw)
             - faire le meme traitement pour tous les contexts; ou bien une boucle do: (se placer ds la bonne director) 
             
    - to Check pods or other stuff, we should always use KUBECTL WITH KUBECONFIG LOCAL FILE AND SPECIFY THE CONTEXT (CLUSTER)
    - $kubectl --kubeconfig=clusters.yaml config get-contexts => for all contexts 
    - $kubectl --kubeconfig=clusters.yaml config current-context => to check current context 
    - $kubectl --kubeconfig=clusters.yaml config use-context xxxx_2nd_cluster => to change for a new cluster 
   Mgt w/ kubemci:  
    - wget https://storage.googleapis.com/kubemci-release/latest/bin/linux/amd64/kubemci; install and make it executable;
    - kubemci is going to need a static public IP address; faut reserver une address: 
    - gcloud compute addresses create --global kubemci-ip ;
    - gcloud compute addresses list; 
    - Creer le Ingress object: yaml  file; (inclure le kubemci-ip)
    - $./kubemci create zone-printer --ingress=manifests/ingress.yaml --kubeconfig=clusters.yaml
    KUBEMCI: 
      - Creates Ingress in each cluster 
      - configure a LoadBalancer 
      - creates whats needed for a loadbalancer;
       (Rules, instance groups for cluster, backend services, url maps, target proxies, forwarding rules and health checks)
    check mci: 
      -$ ./kubemci get-status zone-printer; try to connect with the static ip address;
